I"(<h1 id="cs231n-7강">CS231n 7강</h1>

<p>저번시간 복습</p>

<p>internal covariant : 데이터 간의 분포가 달라지면 학습 결과가 달라질 수 있다.</p>

<p>Batch Normalization의 위치 : non-linearble 연산이 필요한 경우</p>

<p>그래서 normalization하는 단계는 2단계(normalization -&gt; network 학습 변수 적용)</p>

<p>모멘텀 기법 + gradient squared term</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="bp">True</span> <span class="p">:</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">vx</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">vx</span> <span class="o">+</span> <span class="n">dx</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">vx</span>
</code></pre></div></div>

<p>여기서 rho값이 velocity의 영향력을 조절하는데, 보통 0.9, 0.99와 같이 높은 값을 준다. 그래서 gradient vector가 바로 반영되는게 아니라 velocity의 영향을 받아서 나아가게 된다.</p>

<h3 id="adam">Adam</h3>

<p>bias correction에 대해서 좀 더 서술하자.</p>

<p>momentum + ada = adam</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">first_moment</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">second_moment</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">)</span> <span class="p">:</span>
	<span class="n">dx</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># for momentum
</span>    <span class="n">first_moment</span> <span class="o">=</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">first_moment</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dx</span>
    <span class="c1"># for RMSProp
</span>    <span class="n">second_moment</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">second_moment</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">dx</span> <span class="o">*</span> <span class="n">dx</span>
    <span class="c1"># bias correction start
</span>    <span class="n">first_unbias</span> <span class="o">=</span> <span class="n">first_moment</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta1</span><span class="o">**</span><span class="n">t</span><span class="p">)</span>
    <span class="n">second_unbias</span> <span class="o">=</span> <span class="n">second_moment</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta2</span><span class="o">**</span><span class="n">t</span><span class="p">)</span>
    <span class="c1"># bias correction end
</span>    <span class="c1"># AdaGrad / RMSProp
</span>    <span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">first_unbias</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">second_unbias</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>
</code></pre></div></div>

<p>여기서 beta2 = 0.999, learning_rate = 1e-3 또는 5e-4</p>

<p>첫째 둘째 모멘트를 계산하고 난 다음에 그 둘에서 unbias 값을 계산한 후, 이를 다음 스텝에서 적용한다. (베타, 알파)</p>

<p>만약 unbias를 계산하지 않으면 다음의 문제가 생긴다. first_moment와 second_moment가 0에서 시작하는데, second_moment는 첫번째 스텝이 지나가도 0에 수렴하게 된다. 이를 보정하기 위해 Bias correction을 한다.</p>

<p>처음에는 learning rate를 높여서 학습하다가 그 이후에는 꾸준히 낮추면서 학습한다. (learning rate decay)</p>

<p>이 기법은 adam보다 sgd에서 더 많이 쓰이고, 부차적인 하이퍼파라미터가 된다. 정확도를 지켜보다가 필요하다 싶을 때 learning rate를 변경하면서.</p>

<p>First-order optimization : 그 시점에서의 접선의 기울기를 구하는 방법 -&gt;  second-order optimization이 나온듯.</p>

<p>1차 미분은 기울기, 2차 미분은 기울기의 양상을 구할수 있다!</p>

<p>Second-order optimization : 2차 미분의 양상을 사용한다. First-order를 사용하는 것보다 좋긴 한데, 사용할 수 있는 곳이 정해져 있다. Newton step. Hessian matrix. 여기서는 learning rate가 없다. 하이퍼파라미터도 없다. Hessian은 N^3를 사용하기 때문에, 딥러닝에서 활용할 수가 없다(무수한 차원을 생각해보라)</p>

<p>그래서 Quasi-Newton에서는 N^2로 줄지만 이래도 딥러닝에 활용하기에는 너무 크다. 만약 full-batch를 시도할거면, L-BFGS를 사용해봐라. (하지만 Adam을 쓰세요…)</p>

<h4 id="beyond-training-error">Beyond Training Error</h4>

<p>regularization에 대해서 다뤄볼 에정.</p>

<p>train과 test(validation)의 학습 결과를 줄이기 위해서 어떤 것을 해야 하나? : 독립적인 여러 모델 쓰고 앙상블 기법을 써서 결과의 평균을 사용하기. 근데 2프로 정도 증가한다고… (ex : imagenet)</p>

<p>좀 더 나아가면 모델들을 저장하고(snapshot) 앙상블로 사용해볼 수 있다. 학습 중간중간에 앙상블의 결과를 보고 이를 학습에 반영한다. 그래서 learning rate를 높였다 낮췄다 퐁당퐁당하면서 지나간다.</p>

<p>만약 평균을 낼 때 모델 간의 결과의 gap을 신경쓰지 않는다면 validation에 overfitting하면 되지 않을까 라는 단순한 원리로 접근할 수도 있다. poiyak averaging이라는 기법이 있다.</p>

<p>단일 모델의 성능을 향상시키려면 어떻게 해야할까?</p>

<h4 id="regularization--add-term-to-loss">Regularization : Add term to loss</h4>

<p>Training할 때 random noise를 더하고, testing때는 noise를 평균화.</p>

<p>L1, L2, Elastic net</p>

<p>Fully connected layer -&gt; 어떤 뉴런들을 렌덤하게 반영하지 않는다. 근데 너무 많은 특징을 반영하게 되면 랜덤하게 누락된 뉴런이 특징을 파악할 때 관여하는 경우 불리할 수 있다.</p>

<p>Dropout : Random mask를 쓰는 방법 (&lt;- 후에 복습하기!)</p>

<p>그렇다면 이를 test time에서 어떻게 dropout을 사용할까? Dropout한 만큼 test time에서 값을 증폭해야 한다. 하지만 inverted dropout이라는 것도 있는데 이건 train할때 떨군 확률 p를 나눠주고, test time에서는 이를 그냥 둔다.</p>

<p>average out —&gt; 이거 나중에 복습하기!</p>

<p>dropout이 적용되지 않은 노드에서만 back propagation이 일어난다. 결국 Reularization은 네트워크에 무작위성을 추가해서 train 데이터에 overfitting하는 문제를 막는다.  BN이랑 비슷한 효과를 얻을 수 있다. Dropout은 BN과 달리 자유롭게 조정할 수 있는 파라미터 p(drop 확률)가 존재한다.</p>

<h4 id="data-augmentation">Data Augmentation</h4>

<p>이미지의 일부를 잘라서 변형시켜 이를 test에 사용할 수 있다. 그리고 이 외에도 다양한 방법이 있는데, 핵심은 label을 유지하면서 데이터에 변형을 가하는 방법이다.</p>

<p>Fractional maxpooling : pooling할 지역이 random하게 지정된다.</p>

<p>stochastic depth에 대해서 : 곁보기에는 바로 직전의 결과물이 아닌 몇 스텝 이전의 결과물을 그 다음에 반영하는 걸로 보이는데…</p>

<p>보통은 BN을 많이 쓰지만 overfitting이 해결되지 않는다면 Dropout과 같은 다양한 방법을 추가해볼 수 있다.</p>

<p>transfer learning(꽤 유용한 방법) -&gt; 해커톤 같은 경우에 사용가능하다.</p>

<p>데이터가 얼마 없는 경우에 transfer learning을 사용한다. Fully connected layer쪽을 다시 학습시키는 방법을 사용한다. 비슷한 데이터셋의 경우에는 데이터셋 크기 작으면 선형 분류, 많으면 몇몇 레이어를 잘 튜닝시키고 다른 데이터들이 있는 데이터셋의 경우에는 다르게 대처한다.</p>

<p>데이터가 1M 이하면 transfer learning을 추천한다.</p>

<h1 id="cs231n-09">CS231n-09</h1>

<p>CNN output size calculator</p>

<p>you can use this formula <code class="language-plaintext highlighter-rouge">[(W−K+2P)/S]+1</code>.</p>

<ul>
  <li>W is the input volume - in your case 128</li>
  <li>K is the Kernel size - in your case 5</li>
  <li>P is the padding - in your case 0 i believe</li>
  <li>S is the stride - which you have not provided.</li>
</ul>

<p>파라미터의 수는 96 * 11 * 11 * 3</p>

<p>pooling layer에는 parameter가 없다. 왜냐하면 파라미터는 우리가 학습하는 가중치를 의미하는데, pooling의 연산은 학습하면서 적용할 가중치가 없기 때문이다.</p>

<p>AlexNet의 경우 모델을 2개로 나누어서 학습했는데 이유는 GPU 메모리 용량때문에(…)</p>

<p>VGGNet에 대해서 설명 :</p>

<p>Small filters, Deeper networks.</p>

<p>왜 크기가 작은 필터를 사용했나? 크기가 작은 필터를 여러 레이어에 걸쳐 적용한 것은 크기가 큰 필터를 한번 적용한 것과 같다. ( ex : 3x3 필터 세 번과 7x7 필터 한번 )</p>
:ET